{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58209acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/miniconda3/envs/sentiment/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from string import digits\n",
    "from collections import Counter\n",
    "# from pyvi import ViTokenizer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras.utils.np_utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacde5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"\"\n",
    "data_train = pd.read_csv(PATH+\"dataset/vlsp_sentiment_train.csv\", sep='\\t')\n",
    "data_train.columns =['Class', 'Data']\n",
    "data_test = pd.read_csv(PATH+\"dataset/vlsp_sentiment_test.csv\", sep='\\t')\n",
    "data_test.columns =['Class', 'Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40404463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Mình đã dùng anywhere thế hệ đầu, quả là đầy t...\n",
       "1       Quan tâm nhất là độ trễ có cao không, dùng thi...\n",
       "2       dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...\n",
       "3       logitech chắc hàng phải tiền triệu trở lên dùn...\n",
       "4       Đang xài con m175 cùi mía , nhà xài nhiều chuộ...\n",
       "                              ...                        \n",
       "5095    Mình mua máy về đc 1 ngày mà điện thoại khác g...\n",
       "5096    Có bạn nào dùng f1w ko.mình dùng m cảm thấy qu...\n",
       "5097    Dùng oppo mà bộ nhớ 4gb thì k chơi games ...\n",
       "5098    Sao tui thích xài hàng oppo mà lựa toàn mấy đứ...\n",
       "5099    mới mở hộp ,oy mở vào camera mà đã có ảnh chụp...\n",
       "Name: Data, Length: 5100, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c750ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bogo\n",
    "import regex as re\n",
    "import itertools\n",
    "def map_to_unicode():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "\n",
    "def covert_unicode(txt):\n",
    "    dicchar = map_to_unicode()\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "  \n",
    "def preprocess(document):\n",
    "    if type(document) is not str:\n",
    "      document = str(document)\n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    #remove\n",
    "  \n",
    "    # remove html character\n",
    "    document = re.sub(r'<[^>]*>', '', document)\n",
    "\n",
    "    #convert all char to unicode\n",
    "    document = covert_unicode(document)\n",
    "\n",
    "    #remove adjacent identical characters\n",
    "    document = ''.join(c[0] for c in itertools.groupby(document))\n",
    "\n",
    "    #uwf=>ừ,....\n",
    "    document = bogo.process_sequence(document)\n",
    "\n",
    "    # remove error character\n",
    "    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\n",
    "\n",
    "    # remove multiple space character\n",
    "    document = re.sub(r'\\s+', ' ', document).strip()\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af8e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mình đã dùng anywhere thế hệ đầu quả là đầy th...\n",
       "1       quan tâm nhất là độ trễ có cao không dùng thi ...\n",
       "2       dag xài con cùi bắp 98k pin trâu mỗi tội đánh ...\n",
       "3       logitech chắc hàng phải tiền triệu trở lên dùn...\n",
       "4       đang xài con m175 cùi mía nhà xài nhiều chuột ...\n",
       "                              ...                        \n",
       "5095    mình mua máy về đc 1 ngày mà điện thoại khác g...\n",
       "5096    có bạn nào dùng f1ư ko mình dùng m cảm thấy qu...\n",
       "5097    dùng ôp mà bộ nhớ 4gb thì k chơi games đc đâu ...\n",
       "5098    sao tui thích xài hàng ôp mà lựa toàn mấy đứa ...\n",
       "5099    mới mở hộp oy mở vào camera mà đã có ảnh chụp ...\n",
       "Name: Data, Length: 5100, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['Data'] = data_train['Data'].map(lambda x: preprocess(x))\n",
    "data_train['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc4cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "Data     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8bf40bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1700\n",
       " 1    1700\n",
       " 0    1700\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4027abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import unidecode\n",
    "import bogo\n",
    "\n",
    "def read_file(file_path):\n",
    "    fi = open(file_path, 'r', encoding='utf-8')\n",
    "    ls = fi.readlines()\n",
    "    return ls\n",
    "\n",
    "'''load dictionary to mapping word'''\n",
    "vowel_file = open(PATH+'correct_teencode_stopword/vietnamese_vowel.json', encoding='utf-8')\n",
    "vowel_dic = json.load(vowel_file)\n",
    "\n",
    "short_word_file = open(PATH+'correct_teencode_stopword/short_word.json', encoding='utf-8')\n",
    "short_word_dic = json.load(short_word_file)\n",
    "\n",
    "single_word_dic = read_file(PATH+'correct_teencode_stopword/unidecode_vietnamese_dic.txt')\n",
    "single_word_dic = [re.sub('\\n','', s) for s in single_word_dic]\n",
    "\n",
    "\n",
    "def replace_one_one(word, dictionary):\n",
    "    new_word = dictionary.get(word,word)\n",
    "    return new_word\n",
    "def correct_vowel(sent, vowel_dictionary):\n",
    "    '''mapping a`, a\\ --> à, ....'''\n",
    "    words = sent.split()\n",
    "    pattern = r'[aăâeêuưiyoôơ][.`~?\\']'\n",
    "    sent = \"\"\n",
    "    for word in words:\n",
    "        p = re.search(pattern, word)\n",
    "        new_word = word\n",
    "        if p:\n",
    "            idx = p.span()\n",
    "            replace_vowel = vowel_dictionary[word[idx[0]]][word[idx[0] + 1]]\n",
    "            new_word = re.sub(pattern, replace_vowel, new_word)\n",
    "        sent += new_word + ' '\n",
    "    return sent\n",
    "\n",
    "def correct_teencode(sent):\n",
    "    sent = preprocess(sent)\n",
    "    sent = correct_vowel(sent, vowel_dic)\n",
    "\n",
    "    words = sent.split()\n",
    "    sent = \"\"\n",
    "    for word in words:\n",
    "        new_word = \"\"\n",
    "        if word[-1] in [',',';']:\n",
    "            new_word = replace_one_one(word[:-1], short_word_dic)\n",
    "            sent += new_word + word[-1]\n",
    "        else:\n",
    "            new_word = replace_one_one(word, short_word_dic)\n",
    "            sent += new_word\n",
    "        sent += ' '\n",
    "    return sent[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf624f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fixteencode = data_train.copy()\n",
    "data_fixteencode['Data'] = data_fixteencode['Data'].map(lambda x: correct_teencode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428a597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mình đã dùng anywhere thế hệ đầu quả là đầy th...\n",
       "1       quan tâm nhất là độ trễ có cao không dùng thi ...\n",
       "2       dag xài con cùi bắp 98k pin trâu mỗi tội đánh ...\n",
       "3       logitech chắc hàng phải tiền triệu trở lên dùn...\n",
       "4       đang xài con m175 cùi mía nhà xài nhiều chuột ...\n",
       "                              ...                        \n",
       "5095    mình mua máy về được 1 ngày mà điện thoại khác...\n",
       "5096    có bạn nào dùng f1ư không mình dùng m cảm thấy...\n",
       "5097    dùng ôp mà bộ nhớ 4gb thì không chơi games đượ...\n",
       "5098    sao tui thích xài hàng ôp mà lựa toàn mấy đứa ...\n",
       "5099    mới mở hộp rồi mở vào camera mà đã có ảnh chụp...\n",
       "Name: Data, Length: 5100, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fixteencode['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9925fa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([data_fixteencode, data_train])\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0afaa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    2277\n",
       "-1    2125\n",
       " 1    2007\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_train.drop_duplicates()\n",
    "data_train = data_train.dropna()\n",
    "data_train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dec302c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "Data     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3744e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       nói thiệt là mình thì thì chuột nào mình cũng ...\n",
       "1       đang dùng mx1 cũng ngon nhưng chưa đầy năm mà ...\n",
       "2       chưa thấy đc điểm thuyết phục để mua nhất là v...\n",
       "3       những phần xem báo tra cứu bản đồ dịch vụ dùng...\n",
       "4       đúng là mua ở việt nam không ứng dụng được gì ...\n",
       "                              ...                        \n",
       "1045                                              30 củ à\n",
       "1046    aple bán dc thi samsung cũng lời nhiêu người k...\n",
       "1047    có thể giúp android vượt trội so với ios chớ c...\n",
       "1048    mẹ mình từng sang đài loan và có mua 1 cái iph...\n",
       "1049    tùng minh nguyễn điện thoại của vk bị như này ...\n",
       "Name: Data, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['Data'] = data_test['Data'].map(lambda x: preprocess(x))\n",
    "data_test['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371c248a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    350\n",
       " 1    350\n",
       " 0    350\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3fcabd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       nói thiệt là mình thì thì chuột nào mình cũng ...\n",
       "1       đang dùng mx1 cũng ngon nhưng chưa đầy năm mà ...\n",
       "2       chưa thấy được điểm thuyết phục để mua nhất là...\n",
       "3       những phần xem báo tra cứu bản đồ dịch vụ dùng...\n",
       "4       đúng là mua ở việt nam không ứng dụng được gì ...\n",
       "                              ...                        \n",
       "1045                                              30 củ à\n",
       "1046    aple bán được thi samsung cũng lời nhiêu người...\n",
       "1047    có thể giúp android vượt trội so với ios chớ c...\n",
       "1048    mẹ mình từng sang đài loan và có mua 1 cái iph...\n",
       "1049    tùng minh nguyễn điện thoại của vợ bị như này ...\n",
       "Name: Data, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['Data'] = data_test['Data'].map(lambda x: correct_teencode(x))\n",
    "data_test['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10b2b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    0\n",
       "Data     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1165f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['Data']\n",
    "y_train = data_train['Class']\n",
    "X_test = data_test['Data']\n",
    "y_test = data_test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "249d2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bd744c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfVectorizer(max_features=10000)\n",
    "X_train = tfidfconverter.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "037f3706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6409 - Test set size: 1050\n",
      "Vocabulary size: 6333\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size: {} - Test set size: {}\".format(X_train.shape[0],X_test.shape[0]))\n",
    "print(\"Vocabulary size: {}\".format(len(tfidfconverter.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25bdc738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  11.719604015350342 s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training time: ', time.time() - start_time, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df28d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time is  1.2424347400665283 s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "X_test = tfidfconverter.transform(X_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Prediction time is ', time.time() - start_time, 's.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10384696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\t 0.7135851173523063\n",
      "Recall:\t\t 0.7076190476190476\n",
      "F1:\t\t 0.7088269357969691\n",
      "Accuracy:\t 0.7076190476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Precision:\\t\", metrics.precision_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
    "print(\"Recall:\\t\\t\", metrics.recall_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
    "print(\"F1:\\t\\t\", metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred)))\n",
    "print(\"Accuracy:\\t\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2c51c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.69      0.70       350\n",
      "           0       0.64      0.73      0.68       350\n",
      "           1       0.79      0.71      0.75       350\n",
      "\n",
      "    accuracy                           0.71      1050\n",
      "   macro avg       0.71      0.71      0.71      1050\n",
      "weighted avg       0.71      0.71      0.71      1050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c42195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
